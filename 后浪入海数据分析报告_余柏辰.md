# 后浪入海——哔哩哔哩评论数据分析

## 余柏辰

**注**：本项目已在我的个人GitHub上开源发布，项目的完整代码详见[这里](https://github.com/Jamesyu420/bilibili-commentdata-analysis)。

**摘要**：在互联网上，我们常常关注这样一系列问题：我们的用户或受众是谁？他们对接收到的讯息有怎样的态度？本项目实现了一个对[哔哩哔哩视频网](https://www.bilibili.com/)（以下简称b站）评论区的数据分析小程序。通过对用户输入的av号或BV号（或给定json格式的数据文件），爬取对应视频的评论区有效数据，对其进行数据清洗后进行初步的描述性统计分析。然后通过调用第三方库，实现如词云、情感分析等功能，均通过直观的图表格式给出分析结论。本研究报告从问题背景说起，讲解了问题求解与代码实现的全过程，也图文并茂地展示了用该程序进行数据分析的实例。

## 问题背景

该项目的问题意识与灵感来自互联网上对哔哩哔哩官方视频[《后浪》](https://www.bilibili.com/video/BV1FV411d7u7)的广泛争论，我想要对b站评论区用户的反应进行数据分析。刚好这时b站推出了第二弹视频[《入海》](https://www.bilibili.com/video/BV1tC4y1H7yz)，于是可以进行对比分析。然而听说还可能有第三弹，于是决定将其做成一个对b站任意视频评论区进行数据分析的小工具，然后用它进行分析研究。

事实上，由于互联网或是新媒体的高度圈层化，这样的分析有助于我们认清互联网舆论的现状及形成过程。

## 模型建立

将爬取来的数据简单整理后保存至json文件，便于重复使用。在分析时导入DataFrame中进行操作，每一行即为单个评论的全部信息。

## 问题求解与实现

注：我在编程初期采用的是多文件的脚本编码方式，这有助于模块化地发现错误和更新功能；后期由于要制作GUI接口，就直接将所有的函数放到一个文件来添加GUI功能。因此，下面的代码多为主干代码，仅用于展示算法和编码思路，详见GitHub上[master分支](https://github.com/Jamesyu420/bilibili-commentdata-analysis/tree/master)；完整代码在[这里](https://github.com/Jamesyu420/bilibili-commentdata-analysis)。

### **数据获取**

由于b站在robots.txt中明确很多不允许爬取的内容且进行了一系列反爬处理，我们并不直接从b站视频地址上爬取数据，而是找到其API站点进行爬取。这样既便捷，数据格式也相对整齐。因此，这样的爬取只需要使用requests库的get方法即可完成，代码如下。

```py
while True:
    # noinspection PyBroadException
    try:
        url = "https://api.bilibili.com/x/reply?type=1&oid={0}&nohot=1&sort=0&pn={1}".format(aid, j)
        html = get(url)
        data = loads(html.text)
        for i in range(0, 20):  # 每页20条评论
            timeArray = localtime(data['data']['replies'][i]['ctime'])  # 时间戳
            date.append(strftime("%Y-%m-%d %H:%M:%S", timeArray))
            level.append(str(data['data']['replies'][i]['member']['level_info']['current_level']))  # 用户等级
            txt = data['data']['replies'][i]['content']['message']  # 评论内容
            txt = sub('\n', '', txt)
            txt = sub('\r', '', txt)
            text.append(txt)
            like.append(str(data['data']['replies'][i]['like']))  # 赞同数
        j += 1
    except Exception:
        break
```

此外，由于很多数据数据量过大（如我们提到的《后浪》《入海》，均有数万条评论），每次新爬取都要耗时数分钟，于是我们制作了已有数据导入的接口，通过设置flag标记变量以决定每次是否要去爬取新数据。

事实上，如果采用多线程爬虫是解决该问题的一种有效路径，可以显著提高爬取速度，将在以后逐步完善。

### **数据处理与数据清洗**

从爬取好或加载的json文件中读取数据至DataFrame结构的df数据表，在预处理时实现jieba分词并添加至DataFrame中，这样做的好处是分担后面的运行时间，提高数据分析的操作体验。

此外，由于爬取时不时会出现连续两行数据相同的情况，我们调用pandas库的数据清理方法进行简单的清洗。诚然，这样粗暴的清洗会导致如“来啦！”之类的评论减少，但这并不影响我们的分析————反而有一定好处，这意味着我们在后面制作词云时不用考虑大量在互联网上被使用却无意义的语汇。

```py
df = pd.read_json(jsonfile)
df['cut'] = pd.Series(dtype=np.float64)
for i in range(0, df.shape[0]):
    text = df['text'].iloc[i]
    txt_cut = lcut(text, cut_all=False)
    txt_cut = ' '.join(txt_cut)
    df['cut'].iloc[i] = txt_cut
# data cleaning
df.drop_duplicates(inplace=True)
df.dropna(inplace=True)
```

### **算法和具体功能的实现**

#### BV号与av号互转

由于b站的迅速扩张或是对Youtube的单纯模仿，他们认为原有的顺序排列的av号不能满足需求，于是将视频的默认序号改为BV号。然而，其转换算法已经被[破解](https://www.zhihu.com/question/381784377/answer/1099438784),即base58的算法。

我们要做到对于用户需要分析的视频，输入任意一种视频代号即可开始工作。考虑到至少目前av号依旧可以使用，API也是提供的av号版本。我们首先识别视频号的类型，若为BV号则通过下面的脚本转换为av号，便于后续处理。

```py
# 作者：mcfx
def bv2av(bv):
    table = 'fZodR9XQDSUm21yCkr6zBqiveYah8bt4xsWpHnJE7jL5VG3guMTKNPAwcF'
    tr = {}
    for i in range(58):
        tr[table[i]] = i
    s = [11, 10, 3, 8, 4, 6]
    xor = 177451812
    add = 8728348608
    r = 0
    for i in range(6):
        r += tr[bv[s[i]]] * 58 ** i
    return (r - add) ^ xor
```

#### 描述性统计

这个部分我们通过matplotlib的pyplot工具绘制一些图表，以助于我们对该视频评论区有初步认识。

第一个图是用户等级饼状图，用以分析视频的受众，尤其是那些被其吸引或争论而评论的观众。

这里要普及一下b站的等级制。b站有0-6级共七个等级，与用户权限直接关联。而不同于QQ等软件对等级的无限制，b站保持了较严格的水准。一般情况下，6级号或者是入站时间长、了解很多相关知识的老用户，要么是某一领域的优秀up主，或者是氪金用户。而0级号则是注册而未通过答题的（近年来题目已经日益简单）。因此，对b站不同等级用户的观察就显得很有意义。如生活区的讨论质量就普遍低于动漫区（与讨论门槛有关）。

```py
def pie(data, ax):
    # 用户等级饼状图——视频受众分析
    x = data['level'].value_counts().sort_index(ascending=True)
    ax.pie(x, labels=list(x.index), startangle=180, shadow=True, autopct='%1.2f%%')
    ax.set(title="评论等级分布")
    ax.grid()
```

后两个图分别为等级——点赞散点图和等级时序图，主要关注谁在主导舆论。我们常说互联网拉近了人与人的距离或使人更加平等，是这样吗？事实上，互联网往往复制甚至放大了现实社会中的关系。先来的人，有时并不只是因为碰巧刷到而获得较多点赞；而等级低的评论也很难浮在上面。我们会在后面的数据分析章节中给出实例。

```py
def scatter(data, ax):
    x = data['level'].sort_index(ascending=True)
    y = data['like'].sort_index(ascending=True)
    ax.scatter(x, y, marker='.')
    ax.set_title("等级——点赞散点图")
    ax.grid()
```

```py
def timeseries(data, ax):
    x = data['date']
    y = data['level']
    ax.plot_date(x, y, )
    ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))
    ax.xaxis.set_major_locator(AutoDateLocator(maxticks=8))
    ax.legend(['评论'], loc='upper right')
    ax.set_title("用户等级时序分析")
    ax.set_ylabel("等级")
    ax.grid()
```

#### 制作词云

基于前面通过jieba处理好的数据，我们通过第三方库wordcloud生成词云。其中用到了Pillow库以创建背景图（轮廓外需为全白），然后通过我们熟悉的matplotlib库中的pyplot工具弹窗生成词云图，这在我们的GUI编程中显得恰如其分。

```py
def wordcloud(series):
    text_cut = ""
    for i in series:
        text_cut += i
    stop_words = open(r"data/stopwords.txt", encoding='utf-8').read().split('\n')
    background = Image.open(r"data/iconimage.png")
    graph = np.array(background)
    word_cloud = WordCloud(font_path="C:/Windows/Fonts/simfang.ttf", background_color="white", mask=graph,
                           stopwords=stop_words)
    word_cloud.generate(text_cut)
    plt.subplots(figsize=(12, 8))
    plt.imshow(word_cloud)
    plt.axis("off")
    plt.savefig("clouds.png",dpi=300)
    plt.show()
```

#### 情感分析

接下来进入了自然语言处理（NLP）的领域。这里先介绍一下情感分析的步骤。由于中文的特殊性，我们首先要进行分词，然后划分数据集，将文本变为电脑可以识别的词向量，然后喂入分类器即可。

我们这个版本采用的是第三方库snownlp，然而相比于我们前面用到的jieba，它的分词性能较差。由于其采用的是Naive Bayes分类器，限于能力我也很难在这个版本中给出更好的优化（如果只是单纯地用jieba分词替代效果还不如已经造好轮子的snownlp），因此这也是这个版本的一大遗憾。

```py
def feeling():
    global df
    df['sentiments'] = pd.Series(dtype=np.float64)
    df['result'] = pd.Series(dtype=str)
    for i in range(0, df.shape[0]):
        text = SnowNLP(df['text'].iloc[i])
        df['sentiments'].iloc[i] = text.sentiments
        if text.sentiments > 0.7:
            df['result'].iloc[i] = "积极"
        else:
            df['result'].iloc[i] = "消极"
```

上面展示的代码仅为sentiments列的构造过程，我们还使用matplotlib进行了可视化展示，包括饼状图和时序图。饼状图可以帮我们清晰地看到两方人数比，且后续可以通过Echarts加入分等级下钻饼状图的功能，以观察不同人群用户的态度；而时序图则可以清晰地表明何种舆论在何时“入场”，在后面的实例分析中会举例说明。

但我们也意识到了深度学习的方法，可以通过搭建RNNs下的LSTM模型大幅度地改善效果。但这也存在弊病，即能否找到可以适应所有类型评论的数据集——至少目前还比不过snownlp。因此，若想实现情感分析的有效改进并非易事，希望在后续版本可以做到。

#### GUI接口设计

作为一个脚本函数拼凑而成的小工具，实无必要大动干戈请来PyQt这样的大家伙，简单的tkinter已经足以。当然，为了美观（与新系统接轨），我们也调入了tkinter库中的ttk工具，使之更现代化。

![GUI界面图](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/GUI.png)

在具体的GUI设计中，我们将界面分为上下两个Frame，frm_top包括一个文本框、用以接收用户输入视频号的单行输入框以及确认按钮。frm_bottom则包括四个按钮，功能分别为导入数据、生成词云、用户分析、情感分析。其余三个按钮实现的功能前面已经介绍过，这里不再赘述。而其中“导入数据”按钮通过filedialog.askopenfilename方法获取用户想要导入的数据并传至前面的datapre函数中，获得对应的DataFrame。

```py
def dataFind():
    root = Tk()
    root.withdraw()
    filepath = filedialog.askopenfilename()
    global flag
    flag = False
    datapre(filepath)
    flag = True
```

此外，程序还设计了菜单栏，包括获取目录功能、程序功能介绍及帮助和原创声明等。

### **小结**

开发环境：PyCharmEdu + vscode + Jupyter Notebook

调用包：已由pipreqs自动生成至[requirements.txt](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/requirements.txt),具体为：

    python==3.7
    requests==2.23.0
    pandas==1.0.3
    numpy==1.18.4
    wordcloud==1.7.0
    matplotlib==3.2.1
    jieba==0.42.1
    snownlp==0.12.3
    Pillow==7.1.2

本章节主要介绍了我编写这个项目的主要方法和功能，其中也有一些缺憾，或者说展望吧。正如我在项目摘要中说的那样，这只是个开始，希望以后可以将这个项目填充的更加丰富。

1. 挖掘更多的描述性统计图表
2. 大规模的API爬取耗时过长，可以通过多线程爬虫高速爬取
3. 自己构建更准确的分类器，以实现更好的情感分析效果
4. 可以对比不同平台（如网易云音乐）评论区的热词频率，进而分析不同软件受众的特点

## 数据分析实例

### **bilibili晚会 2019最美的夜**

2020年跨年夜，b站开启了直播和年轻人一起跨年，这场晚会因其内容丰富直接，形式创新多元，主题贴近用户收到了不少b站用户的喜爱。之所以提到年轻人，是为了引入后面的主题——“后浪入海”。何以见得呢？我们通过晚会视频的评论区词云图来一探究竟。

![晚会词云](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/Eve2019_clouds.png)

作为一场晚会，充满尖叫声再正常不过了。然而我们注意到，b站原有的文化符号如“动漫”“二次元”在这里不在占据主流位置，取而代之的是多元的文化，包括音乐、游戏等等，因此，年轻人这一主题被正式摆在了b站面前，也正是这样的市场反应促使b站正式把这一话题推至台前供大家讨论。

此外，如果我们根据上图的“越来越”“永远”“会员”等词转入观察评论区用户的属性，也能发现这个视频的受众以5级为主。

![晚会用户分析](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/Eve2019_stats.png)

这时大家可能不免产生了疑惑：为什么6级用户只占了4%，且并没有收获想象中的这么多赞？这是因为，除去流量较大的up主之外，作为视频观看者的6级用户大多为b站原住民——动漫及二次元爱好者。对他们而言，b站快速地扩张如同侵占了自己的领地一样，因此他们并不一定对这样盛大的晚会产生特别的好感，而是会选择观看“拜年祭”——这是春节期间专门的动漫狂欢。因而从情感分析图表中也能看出并不是所有人都如此喜爱这场晚会。（当然，不得不承认的是，很多人喜欢在互联网上表达喜爱时“大哭”，因此很大程度上影响了情感分析的效果，这里就不展示情感分析图了。）

从统计学意义上来看，数据偏差总是难以避免的。然而，如果能从这种偏差背后看到更有意义的东西（如喜好“大哭”的特质），那也是数据的价值体现。

### **《后浪》与《入海》**

终于来到了开头提及的b站官方视频——《后浪》与《入海》。我们先从这两幅图开始说起。

![后浪用户分析](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/Waves_stats.png)

![入海用户分析](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/RunIntoSea_stats.png)

你能区分出来哪个是那个视频的评论用户分析吗？结合我们前面提到的b站近年来的飞速主流化，我们在“等级——点赞图”中发现后者是更为普遍的b站一般话题的分布图。结合我们观察到《后浪》更为“出圈”，故应为第一张图片；而相对没那么耀眼的《入海》则是后者。

《后浪》引起争议的同时也吸引了很多较新的用户加入讨论，从而激发出很多低级高赞评论。6级用户凭借3%的占有率获得了绝大部分的中高赞评论，说明这样的话题同样引起了他们的注意。事实上，如果我们用Echarts之类的工具做一些分等级对比分析，不难发现6级用户的消极率是最高的。

进一步分析，下面分别《后浪》和《入海》的情感分析图（时序图需要动态放大拖动以更好地观察）。很明显地可以发现，《后浪》比《入海》收获了更多的争议。然而，我们也知道《入海》某种意义上被视作b站对老用户的一种安抚，那么这接近30%的消极又从何而来呢？相信它的词云图可以帮你消解这种困惑。

![入海词云](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/image/RunIntoSea_clouds.png)

正如你所看到的那样，“大哭”再一次占据了词云图的主要位置——不如把消极换成感动好了。事实上，如果采用多分类效果当然会更好，但前提是要有充足的适应性强的数据集。

至此，我们就完成了对两个官方视频的数据分析应用。

### **小结**

在这一部分中，我们通过编写的程序运行了一些数据量极大的实例，发现了互联网评论的圈层化，以及对不同受众会展现截然不同的点赞分布，这样的数据可以帮助从业者或观察者更精准地定位受众，从而生产更有针对性的媒体产品。

另一方面，通过多种图表的综合分析，我们也发现了互联网评论存在很多对数据分析者无效或副作用的评论。然而通过这些副作用我们期待看到更有价值的东西，这也激发了我们对不同平台用户习惯（用户画像刻画）的进一步对比分析。

## 写在后面

第一次独立完成一个小项目还是一个很有趣的体验，虽然学会了git但是没有充分利用。当然还是学到了更多，每一次debug就像与抗原作斗争时产生了新的抗体，让我进一步认识遇见的特性和方法。尤其是在最后写文档的过程中，对程序完成的全过程进行了回顾、总结和反思，对程序的缺点和不足有了进一步的展望。

[MIT](https://raw.githubusercontent.com/Jamesyu420/bilibili-commentdata-analysis/single/LICENSE) © Jamesyu420